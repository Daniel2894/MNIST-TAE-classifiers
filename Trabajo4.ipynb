{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que haremos es importar las librerias necesarias para el trabajo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación leemos los datos de entrenamiento y de prueba de MNIST y los ingresamos en frames para el procesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv(\"MNIST_data/mnist_train.csv\")\n",
    "mnist_test = pd.read_csv(\"MNIST_data/mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el método head para ver la estructura de los datos, con sus etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...    0.608  0.609  0.610  \\\n",
       "0  0  0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "1  4  0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "2  1  0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "\n",
       "   0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "\n",
       "[3 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.658</th>\n",
       "      <th>0.659</th>\n",
       "      <th>0.660</th>\n",
       "      <th>0.661</th>\n",
       "      <th>0.662</th>\n",
       "      <th>0.663</th>\n",
       "      <th>0.664</th>\n",
       "      <th>0.665</th>\n",
       "      <th>0.666</th>\n",
       "      <th>0.667</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   7  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...    0.658  0.659  0.660  \\\n",
       "0  2  0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "1  1  0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "2  0  0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "\n",
       "   0.661  0.662  0.663  0.664  0.665  0.666  0.667  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "\n",
       "[3 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que la columna a categorizar es la primer columna que tiene por titulo \"5\" en el dataset de entramiento y \"7\" en el de prueba, el resto de columnas son los pixeles del dígito.\n",
    "\n",
    "Ahora procedemos a dividir el dataset de entramiento y de prueba en datasets con los valores de los pixeles y otros con las categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_pixels = mnist_train.drop(\"5\", axis=1) # pixeles del digito MNIST del dataset de entrenamiento\n",
    "mnist_train_labels = mnist_train.iloc[:,0] # variable categorica del dataset de entrenamiento\n",
    "mnist_test_pixels = mnist_test.drop(\"7\", axis=1) # pixeles del digito MNIST del dataset de prueba\n",
    "mnist_test_labels = mnist_test.iloc[:,0] # variable categorica del dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "procedemos a mirar el shape de los dataset de entrenamiento para darnos una idea de cuántos columnas y filas tiene cada uno y usamos el método head para ver como quedaron conformados los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59999, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...    0.608  0.609  0.610  \\\n",
       "0  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "1  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "\n",
       "   0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "\n",
       "[2 rows x 784 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_pixels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59999,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    4\n",
       "2    1\n",
       "Name: 5, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_labels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para darnos una idea de los valores del dataset de entrenamiento procedemos a obtener la información descriptiva de éste.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " minimo: 0, \n",
      " maximo: 255, \n",
      " media: 33.31839161605075, \n",
      " mediana: 0.0, \n",
      " valor mas comun: 0\n"
     ]
    }
   ],
   "source": [
    "dataset_info = pd.Series(mnist_train_pixels.values.ravel())\n",
    "print(\" minimo: {}, \\n maximo: {}, \\n media: {}, \\n mediana: {}, \\n valor mas comun: {}\"\n",
    "      .format(dataset_info.min(), dataset_info.max(), \n",
    "              dataset_info.mean(), dataset_info.median(), \n",
    "              dataset_info.value_counts().idxmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que en el dataset encontramos valores entre 0 y 255 que son los colores de los pixeles que conforman el digito.\n",
    "\n",
    "Para mejorar el rendimiento de nuestros clasificadores y ayudar a que los algoritmos iterativos de aprendizaje estadístico sean más rápidos para entrenar vamos a normalizar los valores del dataset, convirtiendo los valores en 0 para los pixeles blancos y 1 para los negros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_pixels = mnist_train_pixels / 255\n",
    "mnist_test_pixels = mnist_test_pixels / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " minimo: 0.0, \n",
      " maximo: 1.0, \n",
      " media: 0.130660359271895, \n",
      " mediana: 0.0, \n",
      " valor mas comun: 0.0\n"
     ]
    }
   ],
   "source": [
    "dataset_info = pd.Series(mnist_train_pixels.values.ravel())\n",
    "print(\" minimo: {}, \\n maximo: {}, \\n media: {}, \\n mediana: {}, \\n valor mas comun: {}\"\n",
    "      .format(dataset_info.min(), dataset_info.max(), \n",
    "              dataset_info.mean(), dataset_info.median(), \n",
    "              dataset_info.value_counts().idxmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procederemos a obtener la información del primer digito del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image_data = mnist_train_pixels.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengamos su shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_image_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 784 valores, es decir, 784 pixeles que conforman cada digito de MNIST.\n",
    "\n",
    "Vamos a proceder a convertir el vector de 784 datos en una matriz de 28x28, esto se ingresara en la variable first_image y procederemos a graficar cada dato de la matriz con el fin de ver el primer número, que según el primer elemento del dataset de categorías (mnist_train_labels) debería ser un 0, este número también se guardara en la variable first_label para poder titular la gráfica con el digito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = first_image_data.values.reshape(28,28)\n",
    "first_label = mnist_train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a mirar la matriz first_image y a verificar que si sea una matriz 28x28 con el atributo shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2       , 0.62352941, 0.99215686, 0.62352941, 0.19607843,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18823529,\n",
       "        0.93333333, 0.98823529, 0.98823529, 0.98823529, 0.92941176,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.21176471, 0.89019608,\n",
       "        0.99215686, 0.98823529, 0.9372549 , 0.91372549, 0.98823529,\n",
       "        0.22352941, 0.02352941, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.03921569, 0.23529412, 0.87843137, 0.98823529,\n",
       "        0.99215686, 0.98823529, 0.79215686, 0.32941176, 0.98823529,\n",
       "        0.99215686, 0.47843137, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.63921569, 0.98823529, 0.98823529, 0.98823529,\n",
       "        0.99215686, 0.98823529, 0.98823529, 0.37647059, 0.74117647,\n",
       "        0.99215686, 0.65490196, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2       , 0.93333333, 0.99215686, 0.99215686, 0.74509804,\n",
       "        0.44705882, 0.99215686, 0.89411765, 0.18431373, 0.30980392,\n",
       "        1.        , 0.65882353, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18823529,\n",
       "        0.93333333, 0.98823529, 0.98823529, 0.70196078, 0.04705882,\n",
       "        0.29411765, 0.4745098 , 0.08235294, 0.        , 0.        ,\n",
       "        0.99215686, 0.95294118, 0.19607843, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.14901961, 0.64705882,\n",
       "        0.99215686, 0.91372549, 0.81568627, 0.32941176, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99215686, 0.98823529, 0.64705882, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02745098, 0.69803922, 0.98823529,\n",
       "        0.94117647, 0.27843137, 0.0745098 , 0.10980392, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99215686, 0.98823529, 0.76470588, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.22352941, 0.98823529, 0.98823529,\n",
       "        0.24705882, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99215686, 0.98823529, 0.76470588, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.77647059, 0.99215686, 0.74509804,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.99215686, 0.76862745, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.29803922, 0.96470588, 0.98823529, 0.43921569,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99215686, 0.98823529, 0.58039216, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.98823529, 0.90196078, 0.09803922,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02745098, 0.52941176,\n",
       "        0.99215686, 0.72941176, 0.04705882, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.98823529, 0.8745098 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02745098, 0.51372549, 0.98823529,\n",
       "        0.88235294, 0.27843137, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.98823529, 0.56862745, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.18823529, 0.64705882, 0.98823529, 0.67843137,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3372549 , 0.99215686, 0.88235294, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.44705882, 0.93333333, 0.99215686, 0.63529412, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.98823529, 0.97647059, 0.57254902,\n",
       "        0.18823529, 0.11372549, 0.33333333, 0.69803922, 0.88235294,\n",
       "        0.99215686, 0.8745098 , 0.65490196, 0.21960784, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.98823529, 0.98823529, 0.98823529,\n",
       "        0.89803922, 0.84313725, 0.98823529, 0.98823529, 0.98823529,\n",
       "        0.76862745, 0.50980392, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10980392, 0.78039216, 0.98823529, 0.98823529,\n",
       "        0.99215686, 0.98823529, 0.98823529, 0.91372549, 0.56862745,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09803922, 0.50196078, 0.98823529,\n",
       "        0.99215686, 0.98823529, 0.55294118, 0.14509804, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprobamos que la variable si contiene el primer valor en el arreglo de categorias y procedemos a dibujar el primer digito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEPJJREFUeJzt3X+sXGWdx/H3Z1EwSylb6IVtoVJ/dBPRhFJnG7Vqu9I1laCFJVpYIXdFUpYfigGDBnVlsWS7DaJsYF3qwtoqVIhWioC7EoJhTcByaYotsluRVFtb29t0t6VbU1L47h9zai7lzjPTmTNz5t7n80pu7sz5njPn24HPPTPnmTOPIgIzy88fVd2AmVXD4TfLlMNvlimH3yxTDr9Zphx+s0w5/OOcpH+R9KWy17WxTx7nH7skbQZOBg4CLwO/AFYCyyPilQ4fex7wnYg4tcM2Rz7mXwP/AEwGHgEuiYjdZT2+HRkf+ce+D0fEccBpwFLgc8Cd1bb0WpLeDtwBXEz9D9Z+4J8rbSpzDv84ERF7IuIBYBEwKOkdAJK+JWnJofUkXSdpu6Rtki6VFJLeOnJdSccCPwKmStpX/EyVdIykrxfbbituH9Niix8HfhgRj0fEPuBLwF9JOq7M58Fa5/CPMxGxFtgKvO/wmqQFwDXAfOCtwNwGj/F/wIeAbRExofjZBnwBeBcwEzgDmA18ccTj/6+k9zZo7e3AMyP28SvgJeDPjvTfaOVw+MenbcAJoyz/GPBvEfFsROwH/v4IH/fjwI0RsTMihovtLz5UjIg/iYifNth2ArDnsGV7AB/5K+Lwj0+nAKOdSJsKbBlxf8so66RMBX494v6vi2Wt2AdMPGzZRODFI+zBSuLwjzOS/px6+Ec7Am8HRp69n5Z4qNGGgbZRP7F4yBuLZa14lvpbhUN9vhk4BtjU4vZWMod/nJA0UdI5wHepD9FtGGW1+4BPSHqbpD8G/i7xkDuAEyUdP2LZKuCLkgYkTS62/06LLd4NfFjS+4oTijcCqyPCR/6KOPxj3w8lvUj9JfwXgFuAT4y2YkT8CPgn4DHgeeCJonRglHX/i3rYXyhO5E0FlgBDwM+BDcC6YhkAxajAa040Fo/3LPC31P8I7KT+Xv+KI/3HWnn8IZ+MSXobsBE4JiIOVt2P9ZaP/JmRdJ6koyVNAv6R+ti7g58hhz8/lwHDwK+ofyT48mrbsar4Zb9ZpnzkN8vU63q5s8mTJ8f06dN7uUuzrGzevJldu3aplXU7Cn/xWfFbgaOAf42Ipan1p0+fztDQUCe7NLOEWq3W8rptv+yXdBRwO/ULQE4HLpR0eruPZ2a91cl7/tnA8xHxQkS8RP2TZQvLacvMuq2T8J/Cqy8M2VosexVJiyUNSRoaHh7uYHdmVqZOwj/aSYXXjBtGxPKIqEVEbWBgoIPdmVmZOgn/Vl59VdiptH6Fl5lVrJPwPwXMkPQmSUcDFwAPlNOWmXVb20N9EXFQ0lXAf1Af6ruruHLLzMaAjsb5I+Jh4OGSejGzHvLHe80y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFM9naLbxp+nn346Wb/tttsa1lasWJHcdnBwMFn/1Kc+lazPmjUrWc+dj/xmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaY8zm9J69evT9bnz5+frO/du7dhTVJy25UrVybra9asSdZ3796drOeuo/BL2gy8CLwMHIyIWhlNmVn3lXHk/4uI2FXC45hZD/k9v1mmOg1/AD+W9LSkxaOtIGmxpCFJQ8PDwx3uzszK0mn450TELOBDwJWS3n/4ChGxPCJqEVEbGBjocHdmVpaOwh8R24rfO4EfALPLaMrMuq/t8Es6VtJxh24DHwQ2ltWYmXVXJ2f7TwZ+UIzVvg64JyL+vZSurGfWrl2brJ9//vnJ+p49e5L11Fj+xIkTk9seffTRyfquXelBpieeeKJh7Z3vfGdH+x4P2g5/RLwAnFFiL2bWQx7qM8uUw2+WKYffLFMOv1mmHH6zTPmS3nFg//79DWvr1q1LbnvRRRcl69u2bWurp1bMmDEjWb/uuuuS9UWLFiXrc+bMaVhbsmRJctvrr78+WR8PfOQ3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLlcf5x4LLLLmtYu+eee3rYyZFpNr33vn37kvW5c+cm6z/5yU8a1jZs2JDcNgc+8ptlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmfI4/xjQbDz8wQcfbFiLiI72PW/evGT9nHPOSdY/+9nPNqxNnTo1ue2ZZ56ZrE+aNClZf+yxxxrWOn1exgMf+c0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTHmcvw+sX78+WZ8/f36yvnfv3oa11BTZAGeffXayvmrVqmQ9dc08wE033dSwdumllya3HRgYSNbPOCM9SXTq3/7QQw8lt20238GsWbOS9bGg6ZFf0l2SdkraOGLZCZIekfTL4nf60xZm1ndaedn/LWDBYcs+DzwaETOAR4v7ZjaGNA1/RDwO7D5s8UJgRXF7BXBuyX2ZWZe1e8Lv5IjYDlD8PqnRipIWSxqSNDQ8PNzm7sysbF0/2x8RyyOiFhG1ZidwzKx32g3/DklTAIrfO8trycx6od3wPwAMFrcHgTXltGNmvdJ0nF/SKmAeMFnSVuDLwFLgPkmfBH4DfLSbTY51mzZtStaXLVuWrO/ZsydZT72dmjJlSnLbwcHBZH3ChAnJerPr+ZvVq7J///5k/eabb07W+3k+hFY1DX9EXNigdFbJvZhZD/njvWaZcvjNMuXwm2XK4TfLlMNvlilf0luCAwcOJOupr6+G5peXTpw4MVlfuXJlw1qtVktu+/vf/z5Zz9WWLVuqbqHrfOQ3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLlcf4SNPua52bj+M2sWZP+uoS5c+d29PiWJx/5zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMeZy/BNdcc02yHhHJ+rx585J1j+O3p9nz3q1txwof+c0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTHmcv0UPPvhgw9r69euT20pK1j/ykY+01ZOlpZ73Zv9NZs6cWXY7fafpkV/SXZJ2Sto4YtkNkn4raX3xc3Z32zSzsrXysv9bwIJRln8tImYWPw+X25aZdVvT8EfE48DuHvRiZj3UyQm/qyT9vHhbMKnRSpIWSxqSNDQ8PNzB7sysTO2G/xvAW4CZwHbgq41WjIjlEVGLiNrAwECbuzOzsrUV/ojYEREvR8QrwDeB2eW2ZWbd1lb4JU0Zcfc8YGOjdc2sPzUd55e0CpgHTJa0FfgyME/STCCAzcBlXeyxL6TmsX/ppZeS25500knJ+qJFi9rqabw7cOBAsn7DDTe0/dhnnXVWsr506dK2H3usaBr+iLhwlMV3dqEXM+shf7zXLFMOv1mmHH6zTDn8Zply+M0y5Ut6e+ANb3hDsj5lypRkfbxqNpS3ZMmSZH3ZsmXJ+rRp0xrWrr322uS2EyZMSNbHAx/5zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMeZy/B3L+au7U15o3G6e/9957k/WFCxcm66tXr07Wc+cjv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKY/ztygi2qoB3H///cn6rbfe2lZP/eCWW25J1r/yla80rO3Zsye57UUXXZSsr1y5Mlm3NB/5zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMtTJF9zRgJfCnwCvA8oi4VdIJwL3AdOrTdH8sIv6ne61WS1JbNYDf/e53yfqnP/3pZP2SSy5J1k888cSGtSeffDK57be//e1k/ZlnnknWt2zZkqyfdtppDWsLFixIbnvFFVck69aZVo78B4FrI+JtwLuAKyWdDnweeDQiZgCPFvfNbIxoGv6I2B4R64rbLwLPAacAC4EVxWorgHO71aSZle+I3vNLmg6cCfwMODkitkP9DwRwUtnNmVn3tBx+SROA7wOfiYi9R7DdYklDkoaGh4fb6dHMuqCl8Et6PfXg3x0Rh74VcYekKUV9CrBztG0jYnlE1CKiNjAwUEbPZlaCpuFX/VT2ncBzETHyEq4HgMHi9iCwpvz2zKxbWrmkdw5wMbBB0qHvYb4eWArcJ+mTwG+Aj3anxbHv4MGDyfrtt9+erH/ve99L1o8//viGtU2bNiW37dR73vOeZP0DH/hAw9qNN95Ydjt2BJqGPyJ+CjQayD6r3HbMrFf8CT+zTDn8Zply+M0y5fCbZcrhN8uUw2+WKX91d4ve/e53N6zNnj07ue3atWs72nezS4J37NjR9mNPnjw5Wb/ggguS9bH8teO585HfLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUx/lbdOqppzasrV69umEN4I477kjWU9NYd+rqq69O1i+//PJkfcaMGWW2Y33ER36zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFOKiJ7trFarxdDQUM/2Z5abWq3G0NBQes74go/8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmmoZf0jRJj0l6TtKzkq4ult8g6beS1hc/Z3e/XTMrSytf5nEQuDYi1kk6Dnha0iNF7WsRcXP32jOzbmka/ojYDmwvbr8o6TnglG43ZmbddUTv+SVNB84EflYsukrSzyXdJWlSg20WSxqSNDQ8PNxRs2ZWnpbDL2kC8H3gMxGxF/gG8BZgJvVXBl8dbbuIWB4RtYioDQwMlNCymZWhpfBLej314N8dEasBImJHRLwcEa8A3wTSs1WaWV9p5Wy/gDuB5yLilhHLp4xY7TxgY/ntmVm3tHK2fw5wMbBB0vpi2fXAhZJmAgFsBi7rSodm1hWtnO3/KTDa9cEPl9+OmfWKP+FnlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMtXTKbolDQO/HrFoMrCrZw0cmX7trV/7AvfWrjJ7Oy0iWvq+vJ6G/zU7l4YiolZZAwn92lu/9gXurV1V9eaX/WaZcvjNMlV1+JdXvP+Ufu2tX/sC99auSnqr9D2/mVWn6iO/mVXE4TfLVCXhl7RA0n9Lel7S56vooRFJmyVtKKYdH6q4l7sk7ZS0ccSyEyQ9IumXxe9R50isqLe+mLY9Ma18pc9dv0133/P3/JKOAjYBfwlsBZ4CLoyIX/S0kQYkbQZqEVH5B0IkvR/YB6yMiHcUy5YBuyNiafGHc1JEfK5PersB2Ff1tO3FbFJTRk4rD5wL/A0VPneJvj5GBc9bFUf+2cDzEfFCRLwEfBdYWEEffS8iHgd2H7Z4IbCiuL2C+v88Pdegt74QEdsjYl1x+0Xg0LTylT53ib4qUUX4TwG2jLi/lQqfgFEE8GNJT0taXHUzozg5IrZD/X8m4KSK+zlc02nbe+mwaeX75rlrZ7r7slUR/tGm/uqn8cY5ETEL+BBwZfHy1lrT0rTtvTLKtPJ9od3p7stWRfi3AtNG3D8V2FZBH6OKiG3F753AD+i/qcd3HJohufi9s+J+/qCfpm0fbVp5+uC566fp7qsI/1PADElvknQ0cAHwQAV9vIakY4sTMUg6Fvgg/Tf1+APAYHF7EFhTYS+v0i/TtjeaVp6Kn7t+m+6+kk/4FUMZXweOAu6KiJt63sQoJL2Z+tEe6jMY31Nlb5JWAfOoX/K5A/gycD9wH/BG4DfARyOi5yfeGvQ2j/pL1z9M237oPXaPe3sv8J/ABuCVYvH11N9fV/bcJfq6kAqeN3+81yxT/oSfWaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5ap/wfxuN1ejGjwMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(first_image, cmap='gray_r')\n",
    "plt.title('Digito: {}'.format(first_label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a hacer un histograma con la variable que contiene los labels de los digitos del dataset para ver que tan distribuidos están los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5923., 6742., 5958., 6131., 5842., 5420., 5918., 6265., 5851.,\n",
       "        5949.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Histograma digitos vs. Frecuencia de digitos')\n",
    "plt.xlabel(\"Digitos\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.hist(mnist_train_labels, edgecolor = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que los datos están aproximadamente distribuidos de manera uniforme lo cual nos permite asegurar que el dataset tiene un buen balance de digitos para entrenar los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística Multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que haremos será importar la librería necesaria para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora instanciamos un objeto de la clase LogisticRegression de Sklearn enviando los siguientes parametros:\n",
    "\n",
    "multi_class = \"multinomial\" para indicar que el problema que queremos resolver es multiclase.\n",
    "\n",
    "Según la documentación de Sklearn, el parámetro solver, es usado para definir cuál es el algoritmo de optimización a usar en nuestro modelo, además, se menciona que \"newton-cg\", \"sag\", \"saga\" y \"lbfgs\" son algoritmos que funcionan bien para problemas multinomiales como es nuestro caso. Se descarta \"liblinear\" por ser un algoritmo que funciona bien para datasets pequeños, contrario al dataset de MNIST. [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html]\n",
    "\n",
    "Vamos a entrenar cuatro modelos con cada uno de los algoritmos de optimización mencionados y compararemos los resultados de cada uno con el fin de ver cual es la mejor opción para nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "solver_algorithms = [\"sag\", \"saga\", \"newton-cg\", \"lbfgs\"]\n",
    "model_accuracy = []\n",
    "classification_reports = []\n",
    "\n",
    "for algorithm in solver_algorithms:\n",
    "    logistic_regression_model = LogisticRegression(solver=algorithm, multi_class='multinomial', max_iter=300)\n",
    "    logistic_regression_model.fit(mnist_train_pixels, mnist_train_labels)\n",
    "    predictions = logistic_regression_model.predict(mnist_test_pixels)\n",
    "    model_accuracy.append(logistic_regression_model.score(mnist_test_pixels, mnist_test_labels))\n",
    "    classification_reports.append(classification_report(mnist_test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación para método de optimizacion: sag\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.96      0.98      0.97      1135\n",
      "          2       0.93      0.90      0.91      1032\n",
      "          3       0.90      0.92      0.91      1010\n",
      "          4       0.94      0.94      0.94       982\n",
      "          5       0.90      0.87      0.88       892\n",
      "          6       0.94      0.95      0.95       958\n",
      "          7       0.93      0.92      0.93      1027\n",
      "          8       0.88      0.88      0.88       974\n",
      "          9       0.91      0.92      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93      9999\n",
      "\n",
      "Reporte de clasificación para método de optimizacion: saga\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.96      0.98      0.97      1135\n",
      "          2       0.93      0.90      0.91      1032\n",
      "          3       0.90      0.91      0.91      1010\n",
      "          4       0.94      0.94      0.94       982\n",
      "          5       0.90      0.87      0.88       892\n",
      "          6       0.94      0.95      0.95       958\n",
      "          7       0.93      0.92      0.93      1027\n",
      "          8       0.88      0.88      0.88       974\n",
      "          9       0.91      0.92      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93      9999\n",
      "\n",
      "Reporte de clasificación para método de optimizacion: newton-cg\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96       980\n",
      "          1       0.96      0.98      0.97      1135\n",
      "          2       0.93      0.90      0.91      1032\n",
      "          3       0.90      0.92      0.91      1010\n",
      "          4       0.94      0.94      0.94       982\n",
      "          5       0.90      0.87      0.88       892\n",
      "          6       0.94      0.95      0.95       958\n",
      "          7       0.93      0.92      0.93      1027\n",
      "          8       0.88      0.88      0.88       974\n",
      "          9       0.91      0.92      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93      9999\n",
      "\n",
      "Reporte de clasificación para método de optimizacion: lbfgs\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.96      0.98      0.97      1135\n",
      "          2       0.93      0.90      0.92      1032\n",
      "          3       0.90      0.91      0.91      1010\n",
      "          4       0.94      0.94      0.94       982\n",
      "          5       0.90      0.87      0.88       892\n",
      "          6       0.94      0.95      0.95       958\n",
      "          7       0.93      0.92      0.93      1027\n",
      "          8       0.88      0.88      0.88       974\n",
      "          9       0.91      0.92      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for report, algorithm in zip(classification_reports, solver_algorithms):\n",
    "    print(\"Reporte de clasificación para método de optimización: \" + algorithm  + \"\\n\" + report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo con el método de optimización sag: 0.9256925692569257\n",
      "Precisión del modelo con el método de optimización saga: 0.9253925392539254\n",
      "Precisión del modelo con el método de optimización newton-cg: 0.9255925592559255\n",
      "Precisión del modelo con el método de optimización lbfgs: 0.9260926092609261\n"
     ]
    }
   ],
   "source": [
    "for accuracy, algorithm in zip(model_accuracy, solver_algorithms):\n",
    "    print(\"Precisión del modelo con el método de optimización \" + algorithm + \": \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede notar que la precisión de los cuatro modelos es similar (93%) siendo **lbfgs** el mejor método de optimización por muy poca diferencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
